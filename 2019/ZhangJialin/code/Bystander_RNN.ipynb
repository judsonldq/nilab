{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "#from keras.layers import Flatten\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from io import StringIO\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-9/qoedata.csv')\n",
    "df2 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-10/qoedata.csv')\n",
    "df3 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-11/qoedata.csv')\n",
    "df4 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-12/qoedata.csv')\n",
    "#df5 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-13/qoedata.csv')\n",
    "df6 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-14/qoedata.csv')\n",
    "#df7 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-15/qoedata.csv')\n",
    "#df8 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-17/qoedata.csv')\n",
    "df9 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-18/qoedata.csv')\n",
    "#df10 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-20/qoedata.csv')\n",
    "df11 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-21/qoedata.csv')\n",
    "df12 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-22/qoedata.csv')\n",
    "#df13 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-23/qoedata.csv')\n",
    "df14 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-24/qoedata.csv')\n",
    "df15 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-25/qoedata.csv')\n",
    "\n",
    "df16 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-26/qoedata.csv')\n",
    "df17 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-27/qoedata.csv')\n",
    "#df18 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-28/qoedata.csv')\n",
    "df19 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-29/qoedata.csv')\n",
    "#df20 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-30/qoedata.csv')\n",
    "df21 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-31/qoedata.csv')\n",
    "#df22 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-32/qoedata.csv')\n",
    "#df23 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-33/qoedata.csv')\n",
    "df24 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-34/qoedata.csv')\n",
    "#df25 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-35/qoedata.csv')\n",
    "#df26 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-36/qoedata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.concat([df1,df2,df3,df4,df6,df9,\n",
    "                df11,df12,df14,df15,\n",
    "                df16,df17,df19,df21,\n",
    "               df24], axis = 0)\n",
    "df = df[df.state4 != 0]\n",
    "df25 = pd.read_csv('/home/zdf/桌面/20181231/data/bola-35/qoedata.csv')\n",
    "df25 = df25[df25.state4 != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>state4</th>\n",
       "      <th>state3</th>\n",
       "      <th>reqInterTime</th>\n",
       "      <th>downTraffic</th>\n",
       "      <th>downTrafficDiff</th>\n",
       "      <th>downTrafficDiffAbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101363</td>\n",
       "      <td>101363</td>\n",
       "      <td>101363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  state4  state3  reqInterTime  downTraffic  downTrafficDiff  \\\n",
       "0           0       1       1           0.0       101363           101363   \n",
       "\n",
       "   downTrafficDiffAbs  \n",
       "0              101363  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>state4</th>\n",
       "      <th>state3</th>\n",
       "      <th>reqInterTime</th>\n",
       "      <th>downTraffic</th>\n",
       "      <th>downTrafficDiff</th>\n",
       "      <th>downTrafficDiffAbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252044</td>\n",
       "      <td>252044</td>\n",
       "      <td>252044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  state4  state3  reqInterTime  downTraffic  downTrafficDiff  \\\n",
       "0           0       1       1           0.0       252044           252044   \n",
       "\n",
       "   downTrafficDiffAbs  \n",
       "0              252044  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df25[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['state4']\n",
    "y_train = np.array(list(y_train))\n",
    "y_train = preprocessing.label_binarize(y_train, classes = [1,2,3,4])\n",
    "\n",
    "y_test = df25['state4']\n",
    "y_test = np.array(list(y_test))\n",
    "y_test = preprocessing.label_binarize(y_test, classes= [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35938\n"
     ]
    }
   ],
   "source": [
    "y_train[0:3]\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化，缩放特征数据\n",
    "df_scaled = preprocessing.normalize(df[['reqInterTime','downTraffic','downTrafficDiff','downTrafficDiffAbs']])\n",
    "df25_scaled = preprocessing.normalize(df25[['reqInterTime','downTraffic','downTrafficDiff','downTrafficDiffAbs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(df_scaled, columns = ['reqInterTime','downTraffic','downTrafficDiff','downTrafficDiffAbs']) \n",
    "X_test = pd.DataFrame(df25_scaled, columns = ['reqInterTime','downTraffic','downTrafficDiff','downTrafficDiffAbs']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reqInterTime</th>\n",
       "      <th>downTraffic</th>\n",
       "      <th>downTrafficDiff</th>\n",
       "      <th>downTrafficDiffAbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reqInterTime  downTraffic  downTrafficDiff  downTrafficDiffAbs\n",
       "0      0.000000      0.57735          0.57735             0.57735\n",
       "1      0.000004      0.57735          0.57735             0.57735\n",
       "2      0.000004      0.57735          0.57735             0.57735"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reqInterTime</th>\n",
       "      <th>downTraffic</th>\n",
       "      <th>downTrafficDiff</th>\n",
       "      <th>downTrafficDiffAbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.116680e-06</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.887917e-07</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.887917e-07</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.473835e-06</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reqInterTime  downTraffic  downTrafficDiff  downTrafficDiffAbs\n",
       "0  0.000000e+00      0.57735          0.57735             0.57735\n",
       "1  1.116680e-06      0.57735          0.57735             0.57735\n",
       "2  9.887917e-07      0.57735          0.57735             0.57735\n",
       "3  9.887917e-07      0.57735          0.57735             0.57735\n",
       "4  2.473835e-06      0.57735          0.57735             0.57735"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntmp1 = {\\n        'request':X_train['reqInterTime'],\\n        'downTraffic':X_train['downTraffic'],\\n        'downTrafficDiff':X_train['downTrafficDiff'],\\n        'downTrafficDiffAbs':X_train['downTrafficDiffAbs']\\n        #'label':df_train['state4']\\n}\\ntmp2 = {\\n        'request':X_test['reqInterTime'],\\n        'downTraffic':X_test['downTraffic'],\\n        'downTrafficDiff':X_test['downTrafficDiff'],\\n        'downTrafficDiffAbs':X_test['downTrafficDiffAbs']\\n        #'label':df_test['state4']\\n}\\n\""
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tmp1 = {\n",
    "        'request':X_train['reqInterTime'],\n",
    "        'downTraffic':X_train['downTraffic'],\n",
    "        'downTrafficDiff':X_train['downTrafficDiff'],\n",
    "        'downTrafficDiffAbs':X_train['downTrafficDiffAbs']\n",
    "        #'label':df_train['state4']\n",
    "}\n",
    "tmp2 = {\n",
    "        'request':X_test['reqInterTime'],\n",
    "        'downTraffic':X_test['downTraffic'],\n",
    "        'downTrafficDiff':X_test['downTrafficDiff'],\n",
    "        'downTrafficDiffAbs':X_test['downTrafficDiffAbs']\n",
    "        #'label':df_test['state4']\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbufferStateRecongnize_train = pd.DataFrame(tmp1)\\ncols_train = list(bufferStateRecongnize_train)\\n#cols_train.insert(0, cols_train.pop(cols_train.index('label')))\\n#bufferStateRecongnize_train = bufferStateRecongnize_train.loc[:, cols_train]\\n\""
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "bufferStateRecongnize_train = pd.DataFrame(tmp1)\n",
    "cols_train = list(bufferStateRecongnize_train)\n",
    "#cols_train.insert(0, cols_train.pop(cols_train.index('label')))\n",
    "#bufferStateRecongnize_train = bufferStateRecongnize_train.loc[:, cols_train]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbufferStateRecongnize_test = pd.DataFrame(tmp2)\\ncols_test = list(bufferStateRecongnize_test)\\n#cols_test.insert(0, cols_test.pop(cols_test.index('label')))\\n#bufferStateRecongnize_test = bufferStateRecongnize_test.loc[:, cols_test]\\n\""
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "bufferStateRecongnize_test = pd.DataFrame(tmp2)\n",
    "cols_test = list(bufferStateRecongnize_test)\n",
    "#cols_test.insert(0, cols_test.pop(cols_test.index('label')))\n",
    "#bufferStateRecongnize_test = bufferStateRecongnize_test.loc[:, cols_test]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.astype('float32')\n",
    "X_test = X_test.values.astype('float32')\n",
    "\n",
    "look_back = 4\n",
    "trainX = []\n",
    "testX = []\n",
    "trainY = []\n",
    "testY = []\n",
    "\n",
    "for i in range(len(X_train)-look_back-1):\n",
    "    traintmp = X_train[i:(i+look_back),0:]\n",
    "    trainX.append(traintmp)\n",
    "    trainY.append(y_train[i+look_back])\n",
    "    \n",
    "trainX = np.reshape(trainX, (len(trainX), look_back, 4))\n",
    "trainY = np.reshape(trainY, (len(trainY),1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_test)-look_back-1):\n",
    "    testmp = X_test[i:(i+look_back),0:]\n",
    "    testX.append(testmp)\n",
    "    testY.append(y_test[i+look_back])\n",
    "    \n",
    "testX = np.reshape(testX, (len(testX), look_back, 4))\n",
    "testY = np.reshape(testY, (len(testY),1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2395, 2395)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testX),len(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0000000e+00, 5.7735026e-01, 5.7735026e-01, 5.7735026e-01],\n",
       "        [1.1166800e-06, 5.7735026e-01, 5.7735026e-01, 5.7735026e-01],\n",
       "        [9.8879173e-07, 5.7735026e-01, 5.7735026e-01, 5.7735026e-01],\n",
       "        [9.8879173e-07, 5.7735026e-01, 5.7735026e-01, 5.7735026e-01]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0, 0, 0]]])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_30 to have 2 dimensions, but got array with shape (35933, 1, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-409-91ac7405424a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           callbacks=[history]) \n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_30 to have 2 dimensions, but got array with shape (35933, 1, 4)"
     ]
    }
   ],
   "source": [
    "#创建一个实例history\n",
    "history = LossHistory()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, dropout = 0.2, activation='tanh', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "model.add(Dense(trainY.shape[1],activation='relu'))\n",
    "model.add(Dense(1,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "model.fit(trainX, trainY, \n",
    "          nb_epoch = 5, \n",
    "          batch_size = 1, \n",
    "          verbose = 1,\n",
    "          validation_data = (testX, testY),\n",
    "          callbacks=[history]) \n",
    "\n",
    "score = model.evaluate(testX, testY, batch_size = 1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#绘制acc-loss曲线\n",
    "history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score,mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preY = model.predict_proba(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score：0.776565\n",
      "recall score：1.000000\n",
      "F1 score：0.874232\n",
      "AUC：0.500000\n"
     ]
    }
   ],
   "source": [
    "print('precision score：%f'%precision_score(testY,test_preY))\n",
    "print('recall score：%f'%recall_score(testY,test_preY))\n",
    "print('F1 score：%f'%f1_score(testY,test_preY))\n",
    "print('AUC：%f'%roc_auc_score(testY,test_preY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 滑动窗口预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence_full(model, data, window_size):  \n",
    "    predicted = []\n",
    "    for i in range(len(data)):\n",
    "        predicted.append(model.predict_proba(testX[i,:,:].reshape(1,testX[i,:,:].shape[0],testX[i,:,:].shape[1]))) \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_sequence_full(model,testX,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9985, 1)"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred).reshape(len(y_pred),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score：0.776565\n",
      "recall score：1.000000\n",
      "F1 score：0.874232\n",
      "AUC：0.500000\n"
     ]
    }
   ],
   "source": [
    "print('precision score：%f'%precision_score(testY,y_pred))\n",
    "print('recall score：%f'%recall_score(testY,y_pred))\n",
    "print('F1 score：%f'%f1_score(testY,y_pred))\n",
    "print('AUC：%f'%roc_auc_score(testY,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重新训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=5):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 1:]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX,dtype = 'float16'), np.array(dataY,dtype = 'int')\n",
    "\n",
    "bola_dataset = bola_videoCatonRecongnize.values\n",
    "bola_dataset = bola_dataset.astype('float16')\n",
    "\n",
    "dynamic_dataset = dynamic_videoCatonRecongnize.values\n",
    "dynamic_dataset = dynamic_dataset.astype('float16')\n",
    "train = dynamic_dataset\n",
    "test = bola_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[np.isinf(train)] = 65000\n",
    "test[np.isinf(test)] = 65000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 5\n",
    "trainx,trainy = create_dataset(train,look_back)\n",
    "testx,testy = create_dataset(test,look_back)\n",
    "trainx = np.reshape(trainx, (trainx.shape[0], look_back, trainx.shape[2]))\n",
    "trainy = np.reshape(trainy, (trainy.shape[0], 1))\n",
    "testx = np.reshape(testx, (testx.shape[0], look_back, testx.shape[2]))\n",
    "testy = np.reshape(testy, (testy.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 1.243e+00],\n",
       "       [2.581e+04, 1.243e+00],\n",
       "       [6.166e+04, 1.243e+00],\n",
       "       [4.589e+04, 1.243e+00],\n",
       "       [3.571e+04, 1.243e+00]], dtype=float16)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# PFA, prob false alert for binary classifier\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# P_TA prob true alerts for binary classifier\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9872 samples, validate on 9990 samples\n",
      "Epoch 1/20\n",
      "9872/9872 [==============================] - 42s 4ms/step - loss: 0.6537 - auc: 0.2271 - val_loss: 0.5760 - val_auc: nan\n",
      "Epoch 2/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5410 - auc: 0.4837 - val_loss: 0.5444 - val_auc: nan\n",
      "Epoch 3/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5267 - auc: 0.4875 - val_loss: 0.5387 - val_auc: nan\n",
      "Epoch 4/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5222 - auc: 0.5112 - val_loss: 0.5381 - val_auc: nan\n",
      "Epoch 5/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5214 - auc: 0.5165 - val_loss: 0.5371 - val_auc: nan\n",
      "Epoch 6/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5202 - auc: 0.5258 - val_loss: 0.5378 - val_auc: nan\n",
      "Epoch 7/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5202 - auc: 0.5274 - val_loss: 0.5362 - val_auc: nan\n",
      "Epoch 8/20\n",
      "9872/9872 [==============================] - 11s 1ms/step - loss: 0.5207 - auc: 0.5234 - val_loss: 0.5370 - val_auc: nan\n",
      "Epoch 9/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5199 - auc: 0.5307 - val_loss: 0.5385 - val_auc: nan\n",
      "Epoch 10/20\n",
      "9872/9872 [==============================] - 11s 1ms/step - loss: 0.5197 - auc: 0.5354 - val_loss: 0.5370 - val_auc: nan\n",
      "Epoch 11/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5198 - auc: 0.5331 - val_loss: 0.5358 - val_auc: nan\n",
      "Epoch 12/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5198 - auc: 0.5319 - val_loss: 0.5383 - val_auc: nan\n",
      "Epoch 13/20\n",
      "9872/9872 [==============================] - 11s 1ms/step - loss: 0.5200 - auc: 0.5274 - val_loss: 0.5380 - val_auc: nan\n",
      "Epoch 14/20\n",
      "9872/9872 [==============================] - 11s 1ms/step - loss: 0.5194 - auc: 0.5354 - val_loss: 0.5377 - val_auc: nan\n",
      "Epoch 15/20\n",
      "9872/9872 [==============================] - 11s 1ms/step - loss: 0.5197 - auc: 0.5324 - val_loss: 0.5386 - val_auc: nan\n",
      "Epoch 16/20\n",
      "9872/9872 [==============================] - 11s 1ms/step - loss: 0.5197 - auc: 0.5325 - val_loss: 0.5373 - val_auc: nan\n",
      "Epoch 17/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5189 - auc: 0.5399 - val_loss: 0.5372 - val_auc: nan\n",
      "Epoch 18/20\n",
      "9872/9872 [==============================] - 10s 1ms/step - loss: 0.5195 - auc: 0.5357 - val_loss: 0.5375 - val_auc: nan\n",
      "Epoch 19/20\n",
      "9872/9872 [==============================] - 11s 1ms/step - loss: 0.5187 - auc: 0.5477 - val_loss: 0.5383 - val_auc: nan\n",
      "Epoch 20/20\n",
      "9872/9872 [==============================] - 11s 1ms/step - loss: 0.5191 - auc: 0.5406 - val_loss: 0.5382 - val_auc: nan\n",
      "9990/9990 [==============================] - 5s 540us/step\n",
      "Test loss: 0.5381748648585978\n",
      "Test accuracy: nan\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(32, dropout = 0.2, activation='tanh', input_shape=(trainx.shape[1],trainx.shape[2])))\n",
    "model1.add(Dense(trainy.shape[1],activation='relu'))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = [auc])\n",
    "model1.fit(trainx, trainy, \n",
    "          nb_epoch = 20, \n",
    "          batch_size = 64, \n",
    "          verbose = 1,\n",
    "          validation_data = (testx, testy))\n",
    "\n",
    "score = model1.evaluate(testx, testy, batch_size = 64)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.473074\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(testx)\n",
    "y_pred = np.array(y_pred).reshape(len(y_pred))\n",
    "testy = testy.reshape(len(testy))\n",
    "print('AUC：%f'%roc_auc_score(testy,y_pred))\n",
    "\n",
    "# y_pred = np.array([1 if i > 0.50 else 0 for i in range(len(y_pred))])\n",
    "# print('precision score：%f'%precision_score(testy,y_pred))\n",
    "# print('recall score：%f'%recall_score(testy,y_pred))\n",
    "# print('F1 score：%f'%f1_score(testy,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2236"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in range(len(testy)) if testy[i] < 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(len(y_pred)) if y_pred[i] < 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lstm不手动追溯前面时刻点\n",
    "auc：验证集nan 测试集0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x = train[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_y = train[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_x = test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_y = test[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(unit_forget_bias=True, recurrent_activation=\"hard_sigmoid\", activation=\"sigmoid\", units=128)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9978 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "9978/9978 [==============================] - 43s 4ms/step - loss: 0.2070 - auc: nan - val_loss: 0.2009 - val_auc: nan\n",
      "Epoch 2/20\n",
      "9978/9978 [==============================] - 8s 767us/step - loss: 0.1521 - auc: nan - val_loss: 0.2013 - val_auc: nan\n",
      "Epoch 3/20\n",
      "9978/9978 [==============================] - 8s 783us/step - loss: 0.1476 - auc: nan - val_loss: 0.2039 - val_auc: nan\n",
      "Epoch 4/20\n",
      "9978/9978 [==============================] - 8s 800us/step - loss: 0.1476 - auc: nan - val_loss: 0.2018 - val_auc: nan\n",
      "Epoch 5/20\n",
      "9978/9978 [==============================] - 8s 784us/step - loss: 0.1476 - auc: nan - val_loss: 0.2023 - val_auc: nan\n",
      "Epoch 6/20\n",
      "9978/9978 [==============================] - 8s 794us/step - loss: 0.1468 - auc: nan - val_loss: 0.2020 - val_auc: nan\n",
      "Epoch 7/20\n",
      "9978/9978 [==============================] - 8s 790us/step - loss: 0.1465 - auc: nan - val_loss: 0.2038 - val_auc: nan\n",
      "Epoch 8/20\n",
      "9978/9978 [==============================] - 8s 786us/step - loss: 0.1459 - auc: nan - val_loss: 0.2023 - val_auc: nan\n",
      "Epoch 9/20\n",
      "9978/9978 [==============================] - 8s 794us/step - loss: 0.1462 - auc: nan - val_loss: 0.2040 - val_auc: nan\n",
      "Epoch 10/20\n",
      "9978/9978 [==============================] - 8s 800us/step - loss: 0.1480 - auc: nan - val_loss: 0.2042 - val_auc: nan\n",
      "Epoch 11/20\n",
      "9978/9978 [==============================] - 8s 781us/step - loss: 0.1466 - auc: nan - val_loss: 0.2074 - val_auc: nan\n",
      "Epoch 12/20\n",
      "9978/9978 [==============================] - 8s 799us/step - loss: 0.1454 - auc: nan - val_loss: 0.2061 - val_auc: nan\n",
      "Epoch 13/20\n",
      "9978/9978 [==============================] - 8s 793us/step - loss: 0.1454 - auc: nan - val_loss: 0.2065 - val_auc: nan\n",
      "Epoch 14/20\n",
      "9978/9978 [==============================] - 8s 797us/step - loss: 0.1454 - auc: nan - val_loss: 0.2046 - val_auc: nan\n",
      "Epoch 15/20\n",
      "9978/9978 [==============================] - 8s 780us/step - loss: 0.1449 - auc: nan - val_loss: 0.2044 - val_auc: nan\n",
      "Epoch 16/20\n",
      "9978/9978 [==============================] - 8s 798us/step - loss: 0.1442 - auc: nan - val_loss: 0.2045 - val_auc: nan\n",
      "Epoch 17/20\n",
      "9978/9978 [==============================] - 8s 779us/step - loss: 0.1455 - auc: nan - val_loss: 0.2042 - val_auc: nan\n",
      "Epoch 18/20\n",
      "9978/9978 [==============================] - 8s 794us/step - loss: 0.1452 - auc: nan - val_loss: 0.2060 - val_auc: nan\n",
      "Epoch 19/20\n",
      "9978/9978 [==============================] - 8s 801us/step - loss: 0.1439 - auc: nan - val_loss: 0.2058 - val_auc: nan\n",
      "Epoch 20/20\n",
      "9978/9978 [==============================] - 8s 816us/step - loss: 0.1442 - auc: nan - val_loss: 0.2055 - val_auc: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f65c22ca358>"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(500, 128, input_length=2))\n",
    "model2.add(LSTM(output_dim=128, activation='sigmoid', recurrent_activation='hard_sigmoid', unit_forget_bias=True))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1))\n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[auc])\n",
    "\n",
    "model2.fit(tr_x, tr_y, \n",
    "          nb_epoch = 20, \n",
    "          batch_size = 64, \n",
    "          verbose = 1,\n",
    "          validation_data = (tt_x, tt_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC：0.684453\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict_proba(tt_x)\n",
    "y_pred = np.array(y_pred).reshape(len(y_pred))\n",
    "tt_y = tt_y.reshape(len(tt_y))\n",
    "print('AUC：%f'%roc_auc_score(tt_y,y_pred))\n",
    "\n",
    "# y_pred = np.array([1 if y_pred[i] > 0.50 else 0 for i in range(len(y_pred))])\n",
    "# print('precision score：%f'%precision_score(tt_y,y_pred))\n",
    "# print('recall score：%f'%recall_score(tt_y,y_pred))\n",
    "# print('F1 score：%f'%f1_score(tt_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(len(y_pred)) if y_pred[i] <= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8471982 , 0.8471982 , 0.8471982 , ..., 0.96054965, 0.96054965,\n",
       "       0.96054965], dtype=float32)"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost加上时序特征\n",
    "auc:验证集0.60 测试集0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[:5000]\n",
    "tr_x = train[:,1:]\n",
    "tr_y = train[:,:1].flatten()\n",
    "tt_x = test[:,1:]\n",
    "tt_y = test[:,:1].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       ...,\n",
       "       [1.000e+00, 0.000e+00, 4.512e+00],\n",
       "       [1.000e+00, 5.736e+03, 4.512e+00],\n",
       "       [1.000e+00, 0.000e+00, 4.512e+00]], dtype=float16)"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tr_x[0:4,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(data,lookback=5): # 对data数据集进行操作，datax包含时序信息\n",
    "    datax = []\n",
    "    datay = []\n",
    "    for i in range(len(data)-look_back-1):\n",
    "        a = list(data[i:(i+look_back), 1:].flatten())\n",
    "        datax.append(a)\n",
    "        b = data[i][0]\n",
    "        datay.append(b)\n",
    "    return np.array(datax),np.array(datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x,tr_y = reconstruct(train)\n",
    "tt_x,tt_y = reconstruct(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
       "       ...,\n",
       "       [   0.  ,    4.51,    0.  , ...,    4.51, 2868.  ,    4.51],\n",
       "       [   0.  ,    4.51, 4304.  , ...,    4.51,    0.  ,    4.51],\n",
       "       [4304.  ,    4.51, 2868.  , ...,    4.51,    0.  ,    4.51]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.], dtype=float16)"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "                     objective= 'binary:logistic', \n",
    "                     nthread=4, \n",
    "                     max_depth=2,\n",
    "                     min_child_weight=4, \n",
    "                     learning_rate =0.1, \n",
    "                     n_estimators=140, \n",
    "                     gamma=0, \n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,    \n",
    "                     scale_pos_weight=1, \n",
    "                     seed=27,\n",
    "                     \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.636229\n",
      "[1]\tvalidation_0-auc:0.673296\n",
      "[2]\tvalidation_0-auc:0.673228\n",
      "[3]\tvalidation_0-auc:0.673152\n",
      "[4]\tvalidation_0-auc:0.673143\n",
      "[5]\tvalidation_0-auc:0.673133\n",
      "[6]\tvalidation_0-auc:0.739203\n",
      "[7]\tvalidation_0-auc:0.738876\n",
      "[8]\tvalidation_0-auc:0.737986\n",
      "[9]\tvalidation_0-auc:0.737831\n",
      "[10]\tvalidation_0-auc:0.739409\n",
      "[11]\tvalidation_0-auc:0.739882\n",
      "[12]\tvalidation_0-auc:0.73942\n",
      "[13]\tvalidation_0-auc:0.739564\n",
      "[14]\tvalidation_0-auc:0.740086\n",
      "[15]\tvalidation_0-auc:0.741567\n",
      "[16]\tvalidation_0-auc:0.741541\n",
      "[17]\tvalidation_0-auc:0.741453\n",
      "[18]\tvalidation_0-auc:0.741598\n",
      "[19]\tvalidation_0-auc:0.741551\n",
      "[20]\tvalidation_0-auc:0.741897\n",
      "[21]\tvalidation_0-auc:0.741632\n",
      "[22]\tvalidation_0-auc:0.742058\n",
      "[23]\tvalidation_0-auc:0.74139\n",
      "[24]\tvalidation_0-auc:0.741651\n",
      "[25]\tvalidation_0-auc:0.74126\n",
      "[26]\tvalidation_0-auc:0.741536\n",
      "[27]\tvalidation_0-auc:0.741306\n",
      "[28]\tvalidation_0-auc:0.741317\n",
      "[29]\tvalidation_0-auc:0.741319\n",
      "[30]\tvalidation_0-auc:0.741296\n",
      "[31]\tvalidation_0-auc:0.732453\n",
      "[32]\tvalidation_0-auc:0.732898\n",
      "[33]\tvalidation_0-auc:0.732797\n",
      "[34]\tvalidation_0-auc:0.722384\n",
      "[35]\tvalidation_0-auc:0.722343\n",
      "[36]\tvalidation_0-auc:0.721968\n",
      "[37]\tvalidation_0-auc:0.722162\n",
      "[38]\tvalidation_0-auc:0.722121\n",
      "[39]\tvalidation_0-auc:0.722123\n",
      "[40]\tvalidation_0-auc:0.716218\n",
      "[41]\tvalidation_0-auc:0.716049\n",
      "[42]\tvalidation_0-auc:0.688209\n",
      "[43]\tvalidation_0-auc:0.686154\n",
      "[44]\tvalidation_0-auc:0.680111\n",
      "[45]\tvalidation_0-auc:0.678041\n",
      "[46]\tvalidation_0-auc:0.679197\n",
      "[47]\tvalidation_0-auc:0.676661\n",
      "[48]\tvalidation_0-auc:0.676755\n",
      "[49]\tvalidation_0-auc:0.676986\n",
      "[50]\tvalidation_0-auc:0.674849\n",
      "[51]\tvalidation_0-auc:0.675594\n",
      "[52]\tvalidation_0-auc:0.67401\n",
      "[53]\tvalidation_0-auc:0.672089\n",
      "[54]\tvalidation_0-auc:0.667629\n",
      "[55]\tvalidation_0-auc:0.662615\n",
      "[56]\tvalidation_0-auc:0.662182\n",
      "[57]\tvalidation_0-auc:0.656431\n",
      "[58]\tvalidation_0-auc:0.659757\n",
      "[59]\tvalidation_0-auc:0.660582\n",
      "[60]\tvalidation_0-auc:0.651725\n",
      "[61]\tvalidation_0-auc:0.659218\n",
      "[62]\tvalidation_0-auc:0.652429\n",
      "[63]\tvalidation_0-auc:0.650413\n",
      "[64]\tvalidation_0-auc:0.650413\n",
      "[65]\tvalidation_0-auc:0.611596\n",
      "[66]\tvalidation_0-auc:0.646304\n",
      "[67]\tvalidation_0-auc:0.64571\n",
      "[68]\tvalidation_0-auc:0.64558\n",
      "[69]\tvalidation_0-auc:0.649493\n",
      "[70]\tvalidation_0-auc:0.650758\n",
      "[71]\tvalidation_0-auc:0.650734\n",
      "[72]\tvalidation_0-auc:0.669184\n",
      "[73]\tvalidation_0-auc:0.659118\n",
      "[74]\tvalidation_0-auc:0.652521\n",
      "[75]\tvalidation_0-auc:0.645755\n",
      "[76]\tvalidation_0-auc:0.631454\n",
      "[77]\tvalidation_0-auc:0.645955\n",
      "[78]\tvalidation_0-auc:0.647277\n",
      "[79]\tvalidation_0-auc:0.645614\n",
      "[80]\tvalidation_0-auc:0.630476\n",
      "[81]\tvalidation_0-auc:0.633408\n",
      "[82]\tvalidation_0-auc:0.623679\n",
      "[83]\tvalidation_0-auc:0.605847\n",
      "[84]\tvalidation_0-auc:0.606365\n",
      "[85]\tvalidation_0-auc:0.602917\n",
      "[86]\tvalidation_0-auc:0.617087\n",
      "[87]\tvalidation_0-auc:0.615372\n",
      "[88]\tvalidation_0-auc:0.6049\n",
      "[89]\tvalidation_0-auc:0.607864\n",
      "[90]\tvalidation_0-auc:0.598073\n",
      "[91]\tvalidation_0-auc:0.599514\n",
      "[92]\tvalidation_0-auc:0.597643\n",
      "[93]\tvalidation_0-auc:0.598322\n",
      "[94]\tvalidation_0-auc:0.590903\n",
      "[95]\tvalidation_0-auc:0.591252\n",
      "[96]\tvalidation_0-auc:0.594197\n",
      "[97]\tvalidation_0-auc:0.595414\n",
      "[98]\tvalidation_0-auc:0.595154\n",
      "[99]\tvalidation_0-auc:0.596323\n",
      "[100]\tvalidation_0-auc:0.602538\n",
      "[101]\tvalidation_0-auc:0.608361\n",
      "[102]\tvalidation_0-auc:0.60811\n",
      "[103]\tvalidation_0-auc:0.608193\n",
      "[104]\tvalidation_0-auc:0.626892\n",
      "[105]\tvalidation_0-auc:0.627816\n",
      "[106]\tvalidation_0-auc:0.628427\n",
      "[107]\tvalidation_0-auc:0.624413\n",
      "[108]\tvalidation_0-auc:0.618769\n",
      "[109]\tvalidation_0-auc:0.619108\n",
      "[110]\tvalidation_0-auc:0.611459\n",
      "[111]\tvalidation_0-auc:0.600239\n",
      "[112]\tvalidation_0-auc:0.60108\n",
      "[113]\tvalidation_0-auc:0.601614\n",
      "[114]\tvalidation_0-auc:0.599629\n",
      "[115]\tvalidation_0-auc:0.59956\n",
      "[116]\tvalidation_0-auc:0.5965\n",
      "[117]\tvalidation_0-auc:0.592886\n",
      "[118]\tvalidation_0-auc:0.607259\n",
      "[119]\tvalidation_0-auc:0.609106\n",
      "[120]\tvalidation_0-auc:0.61562\n",
      "[121]\tvalidation_0-auc:0.61011\n",
      "[122]\tvalidation_0-auc:0.616813\n",
      "[123]\tvalidation_0-auc:0.609511\n",
      "[124]\tvalidation_0-auc:0.619548\n",
      "[125]\tvalidation_0-auc:0.619283\n",
      "[126]\tvalidation_0-auc:0.615201\n",
      "[127]\tvalidation_0-auc:0.614229\n",
      "[128]\tvalidation_0-auc:0.614147\n",
      "[129]\tvalidation_0-auc:0.60599\n",
      "[130]\tvalidation_0-auc:0.605926\n",
      "[131]\tvalidation_0-auc:0.606036\n",
      "[132]\tvalidation_0-auc:0.606956\n",
      "[133]\tvalidation_0-auc:0.605682\n",
      "[134]\tvalidation_0-auc:0.598751\n",
      "[135]\tvalidation_0-auc:0.596714\n",
      "[136]\tvalidation_0-auc:0.596703\n",
      "[137]\tvalidation_0-auc:0.596808\n",
      "[138]\tvalidation_0-auc:0.598416\n",
      "[139]\tvalidation_0-auc:0.598728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=4, missing=None, n_estimators=140,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.fit(tr_x,tr_y,eval_set=[(tt_x,tt_y)],eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "pred = xgb1.predict(tt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.535770703023542"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(pred,tt_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tt_y).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  24,  244],\n",
       "       [ 172, 4549]])"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(tt_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
