{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "#from keras.layers import Flatten\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from io import StringIO\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import keras_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/dave/Desktop/毕设数据/df.csv')\n",
    "df25 = pd.read_csv('/Users/dave/Desktop/毕设数据/df25.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df25['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[:2053]\n",
    "# df25 = df25[:2053]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state4</th>\n",
       "      <th>state3</th>\n",
       "      <th>reqInterTime</th>\n",
       "      <th>downTraffic</th>\n",
       "      <th>downTrafficDiff</th>\n",
       "      <th>downTrafficDiffAbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101363</td>\n",
       "      <td>101363</td>\n",
       "      <td>101363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state4  state3  reqInterTime  downTraffic  downTrafficDiff  \\\n",
       "0       1       1           0.0       101363           101363   \n",
       "\n",
       "   downTrafficDiffAbs  \n",
       "0              101363  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75595"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state4</th>\n",
       "      <th>state3</th>\n",
       "      <th>reqInterTime</th>\n",
       "      <th>downTraffic</th>\n",
       "      <th>downTrafficDiff</th>\n",
       "      <th>downTrafficDiffAbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252044</td>\n",
       "      <td>252044</td>\n",
       "      <td>252044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state4  state3  reqInterTime  downTraffic  downTrafficDiff  \\\n",
       "0       1       1           0.0       252044           252044   \n",
       "\n",
       "   downTrafficDiffAbs  \n",
       "0              252044  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df25[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将特征进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = preprocessing.normalize(df[['reqInterTime','downTraffic','downTrafficDiff','downTrafficDiffAbs']])\n",
    "df25_scaled = preprocessing.normalize(df25[['reqInterTime','downTraffic','downTrafficDiff','downTrafficDiffAbs']])\n",
    "\n",
    "df_train = pd.DataFrame(df_scaled, columns = ['reqInterTime','downTraffic','downTrafficDiff','downTrafficDiffAbs']) \n",
    "df_test = pd.DataFrame(df25_scaled, columns = ['reqInterTime','downTraffic','downTrafficDiff','downTrafficDiffAbs']) \n",
    "df_train['label'] = list(df['state4'])\n",
    "df_test['label'] = list(df25['state4'])\n",
    "\n",
    "cols = list(df_train)\n",
    "cols.insert(0, cols.pop(cols.index('label')))\n",
    "df_train = df_train.loc[:, cols]\n",
    "\n",
    "cols = list(df_test)\n",
    "cols.insert(0, cols.pop(cols.index('label')))\n",
    "df_test = df_test.loc[:, cols]\n",
    "\n",
    "#df_train['label'] = df_train['label'].replace([1,2,3,4],[0.1,0.2,0.3,0.4])\n",
    "#df_test['label'] = df_test['label'].replace([1,2,3,4],[0.1,0.2,0.3,0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>reqInterTime</th>\n",
       "      <th>downTraffic</th>\n",
       "      <th>downTrafficDiff</th>\n",
       "      <th>downTrafficDiffAbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  reqInterTime  downTraffic  downTrafficDiff  downTrafficDiffAbs\n",
       "0      1           0.0      0.57735          0.57735             0.57735"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>reqInterTime</th>\n",
       "      <th>downTraffic</th>\n",
       "      <th>downTrafficDiff</th>\n",
       "      <th>downTrafficDiffAbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  reqInterTime  downTraffic  downTrafficDiff  downTrafficDiffAbs\n",
       "0      1           0.0      0.57735          0.57735             0.57735"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造监督数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.values.astype('float16')\n",
    "test = df_test.values.astype('float16')\n",
    "#设置“输入数据回看”的步数\n",
    "look_back = 4\n",
    "trainX = []\n",
    "testX = []\n",
    "trainY = []\n",
    "testY = []\n",
    "\n",
    "for i in range(len(train)-look_back-1):\n",
    "    traintmp = train[i:(i+look_back),1:]\n",
    "    trainX.append(traintmp)\n",
    "    trainY.append(train[i+look_back,0])\n",
    "    \n",
    "trainX = np.reshape(trainX, (len(trainX), look_back, 4))\n",
    "trainY = np.reshape(trainY, (len(trainY),1))\n",
    "\n",
    "for i in range(len(test)-look_back-1):\n",
    "    testmp = test[i:(i+look_back),1:]\n",
    "    testX.append(testmp)\n",
    "    testY.append(test[i+look_back,0])\n",
    "    \n",
    "testX = np.reshape(testX, (len(testX), look_back, 4))\n",
    "testY = np.reshape(testY, (len(testY),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75590, 4, 4) (75590, 1)\n",
      "[[[0.00e+00 5.77e-01 5.77e-01 5.77e-01]\n",
      "  [3.81e-06 5.77e-01 5.77e-01 5.77e-01]\n",
      "  [3.81e-06 5.77e-01 5.77e-01 5.77e-01]\n",
      "  [3.46e-06 5.77e-01 5.77e-01 5.77e-01]]\n",
      "\n",
      " [[3.81e-06 5.77e-01 5.77e-01 5.77e-01]\n",
      "  [3.81e-06 5.77e-01 5.77e-01 5.77e-01]\n",
      "  [3.46e-06 5.77e-01 5.77e-01 5.77e-01]\n",
      "  [3.46e-06 5.77e-01 5.77e-01 5.77e-01]]]\n",
      "[[1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape,trainY.shape)\n",
    "print(trainX[0:2])\n",
    "print(trainY[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2395, 4, 4) (2395, 1)\n"
     ]
    }
   ],
   "source": [
    "print(testX.shape,testY.shape)\n",
    "#print(testX[0:1])\n",
    "#print(testY[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多类别标签二值化——onehot编码\n",
    "# trainY_binary = preprocessing.label_binarize(trainY, classes = [1,2,3,4])\n",
    "# testY_binary = preprocessing.label_binarize(testY, classes = [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "testY_binary = to_categorical(testY, num_classes=None)\n",
    "trainY_binary = to_categorical(trainY, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY_binary = np.array([i[:4] for i in testY_binary])\n",
    "testY_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY_binary = np.array([i[:4] for i in trainY_binary])\n",
    "trainY_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_predict = np.argmax(np.asarray(self.model.predict(self.validation_data[0])), axis=1)\n",
    "        #val_targ = self.validation_data[1]\n",
    "        val_targ = np.argmax(self.validation_data[1], axis=1)\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='macro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='macro')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        #print('— val_f1: %f — val_precision: %f — val_recall %f' %(_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75590, 4, 4)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trainX = np.concatenate((trainX, np.zeros(shape = (trainX.shape[0],trainX.shape[1],1))),axis = 2)\n",
    "new_testX = np.concatenate((testX, np.zeros(shape = (testX.shape[0],testX.shape[1],1))),axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metrics()\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(LSTM(128, dropout = 0.2, activation='tanh', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "model.add(LSTM(128, input_shape=(new_trainX.shape[1], new_trainX.shape[2])))\n",
    "#model.add(Dense(trainY.shape[1], activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "#model.add(Dense(1))\n",
    "model.compile(\n",
    "            loss = 'categorical_crossentropy', \n",
    "            optimizer = 'adam', \n",
    "            metrics = ['accuracy'])\n",
    "\n",
    "#绘制acc-loss曲线\n",
    "#history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.1252 - acc: 0.0000e+00 - val_loss: 0.4967 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.8085 - acc: 0.3125 - val_loss: 0.4967 - val_acc: 0.7194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdf/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/zdf/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1937 - acc: 1.0000 - val_loss: 0.4966 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2028 - acc: 1.0000 - val_loss: 0.4965 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3326 - acc: 1.0000 - val_loss: 0.4963 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1996 - acc: 1.0000 - val_loss: 0.4961 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2037 - acc: 1.0000 - val_loss: 0.4958 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2026 - acc: 1.0000 - val_loss: 0.4954 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1960 - acc: 1.0000 - val_loss: 0.4950 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1841 - acc: 1.0000 - val_loss: 0.4947 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1877 - acc: 1.0000 - val_loss: 0.4943 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1968 - acc: 1.0000 - val_loss: 0.4939 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1882 - acc: 1.0000 - val_loss: 0.4935 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1850 - acc: 1.0000 - val_loss: 0.4932 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2170 - acc: 1.0000 - val_loss: 0.4929 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2625 - acc: 1.0000 - val_loss: 0.4927 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1808 - acc: 1.0000 - val_loss: 0.4925 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2304 - acc: 1.0000 - val_loss: 0.4925 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2568 - acc: 1.0000 - val_loss: 0.4926 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1577 - acc: 1.0000 - val_loss: 0.4928 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1856 - acc: 1.0000 - val_loss: 0.4931 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2664 - acc: 1.0000 - val_loss: 0.4935 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1918 - acc: 1.0000 - val_loss: 0.4940 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1349 - acc: 1.0000 - val_loss: 0.4947 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1329 - acc: 1.0000 - val_loss: 0.4956 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1490 - acc: 1.0000 - val_loss: 0.4965 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1400 - acc: 1.0000 - val_loss: 0.4976 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1175 - acc: 1.0000 - val_loss: 0.4989 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1177 - acc: 1.0000 - val_loss: 0.5002 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1137 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1062 - acc: 1.0000 - val_loss: 0.5032 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1026 - acc: 1.0000 - val_loss: 0.5048 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0995 - acc: 1.0000 - val_loss: 0.5066 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1031 - acc: 1.0000 - val_loss: 0.5084 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1205 - acc: 1.0000 - val_loss: 0.5104 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1062 - acc: 1.0000 - val_loss: 0.5124 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1751 - acc: 1.0000 - val_loss: 0.5146 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0954 - acc: 1.0000 - val_loss: 0.5169 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0879 - acc: 1.0000 - val_loss: 0.5193 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0803 - acc: 1.0000 - val_loss: 0.5218 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0784 - acc: 1.0000 - val_loss: 0.5243 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0744 - acc: 1.0000 - val_loss: 0.5268 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0706 - acc: 1.0000 - val_loss: 0.5294 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0780 - acc: 1.0000 - val_loss: 0.5320 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1371 - acc: 1.0000 - val_loss: 0.5348 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1133 - acc: 1.0000 - val_loss: 0.5377 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1189 - acc: 1.0000 - val_loss: 0.5407 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0964 - acc: 1.0000 - val_loss: 0.5439 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0583 - acc: 1.0000 - val_loss: 0.5471 - val_acc: 0.7194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0681 - acc: 1.0000 - val_loss: 0.5503 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0688 - acc: 1.0000 - val_loss: 0.5535 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0761 - acc: 1.0000 - val_loss: 0.5568 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0538 - acc: 1.0000 - val_loss: 0.5601 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0532 - acc: 1.0000 - val_loss: 0.5634 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0551 - acc: 1.0000 - val_loss: 0.5667 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0774 - acc: 1.0000 - val_loss: 0.5700 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0522 - acc: 1.0000 - val_loss: 0.5734 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0564 - acc: 1.0000 - val_loss: 0.5768 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0599 - acc: 1.0000 - val_loss: 0.5802 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.5836 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0430 - acc: 1.0000 - val_loss: 0.5870 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0560 - acc: 1.0000 - val_loss: 0.5905 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0499 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0422 - acc: 1.0000 - val_loss: 0.5974 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0394 - acc: 1.0000 - val_loss: 0.6009 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0488 - acc: 1.0000 - val_loss: 0.6044 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0401 - acc: 1.0000 - val_loss: 0.6079 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0317 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0345 - acc: 1.0000 - val_loss: 0.6148 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0581 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0301 - acc: 1.0000 - val_loss: 0.6218 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.6253 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.6287 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.6353 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0483 - acc: 1.0000 - val_loss: 0.6387 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0303 - acc: 1.0000 - val_loss: 0.6421 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.6454 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.6487 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6520 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.6552 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6584 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.6615 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.6646 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.6676 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.6707 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6737 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.6767 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.6796 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6826 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.6855 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.6884 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6912 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6941 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.6969 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.6997 - val_acc: 0.7194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.7025 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.7053 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.7080 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.7108 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.7135 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.7162 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.7192 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.7223 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.7283 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.7312 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.7342 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.7371 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.7400 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0341 - acc: 1.0000 - val_loss: 0.7432 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.7465 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.7499 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.7532 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.7564 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.7596 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7627 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7657 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7687 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7717 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7746 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7775 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7803 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7830 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7858 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7885 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7911 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.7938 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0239 - acc: 1.0000 - val_loss: 0.7967 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.7998 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.8027 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.8057 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.8088 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.8120 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.8151 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.8182 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.8215 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.8248 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.8281 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.8312 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.8343 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.8373 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.8402 - val_acc: 0.7194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.8430 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.8458 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.8488 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.8519 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.8549 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.8578 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2652 - acc: 0.7500 - val_loss: 0.8530 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.4161 - acc: 0.3125 - val_loss: 0.8322 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.1166 - acc: 0.5000 - val_loss: 0.8003 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.5745 - acc: 0.5625 - val_loss: 0.7638 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7833 - acc: 0.6875 - val_loss: 0.7279 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.6988 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.6751 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.6558 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.6399 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.6268 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.6160 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.6070 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.5995 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0337 - acc: 1.0000 - val_loss: 0.5934 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0333 - acc: 1.0000 - val_loss: 0.5882 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.5840 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0357 - acc: 1.0000 - val_loss: 0.5805 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0363 - acc: 1.0000 - val_loss: 0.5777 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.5754 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0438 - acc: 1.0000 - val_loss: 0.5736 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0401 - acc: 1.0000 - val_loss: 0.5723 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0427 - acc: 1.0000 - val_loss: 0.5713 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0434 - acc: 1.0000 - val_loss: 0.5707 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0396 - acc: 1.0000 - val_loss: 0.5703 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0402 - acc: 1.0000 - val_loss: 0.5702 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0419 - acc: 1.0000 - val_loss: 0.5703 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0410 - acc: 1.0000 - val_loss: 0.5706 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0392 - acc: 1.0000 - val_loss: 0.5711 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0395 - acc: 1.0000 - val_loss: 0.5718 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0411 - acc: 1.0000 - val_loss: 0.5726 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0411 - acc: 1.0000 - val_loss: 0.5735 - val_acc: 0.7194\n",
      "Train on 16 samples, validate on 2395 samples\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.5746 - val_acc: 0.7194\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-afe2593891c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnew_testX\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0minput_testX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_trainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_trainY_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_testX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-dda09632d5eb>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mval_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m#val_targ = self.validation_data[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mval_targ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 2\n",
    "batch = 16\n",
    "for _ in range(num_epoch):\n",
    "    for i in range(int(trainX.shape[0]//batch)):\n",
    "        predict_feature = model.predict(new_trainX[i*batch:(i+1)*batch]).reshape(batch,new_trainX.shape[1],1)\n",
    "        input_trainX = np.concatenate((trainX[i*batch:(i+1)*batch], predict_feature),axis=2)\n",
    "        input_trainY_binary = trainY_binary[i*batch:(i+1)*batch]\n",
    "        new_trainX[i*batch:(i+1)*batch] =  input_trainX\n",
    "        \n",
    "        predict_feature = model.predict(new_testX).reshape(new_testX.shape[0],new_testX.shape[1],1)\n",
    "        input_testX = np.concatenate((testX, predict_feature),axis=2)\n",
    "        new_testX =  input_testX\n",
    "        \n",
    "        model.fit(input_trainX, input_trainY_binary, class_weight = 'auto', epochs = 1, batch_size = batch, \\\n",
    "                   verbose = 1, validation_data = (input_testX, testY_binary), callbacks = [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2395/2395 [==============================] - 0s 66us/step\n",
      "Test loss: 0.06692123617549156\n",
      "Test accuracy: 0.8492693110647181\n",
      "Test precision: 0.5440143526317004\n",
      "Test recall: 0.7289868790036939\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(new_testX, testY_binary, batch_size = 16)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', metrics.val_precisions[-1])\n",
    "print('Test recall:', metrics.val_recalls[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 召回、f1分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax结果转换成onehot编码\n",
    "def props_to_onehot(props):\n",
    "    if isinstance(props, list):\n",
    "        props = np.array(props)\n",
    "    a = np.argmax(props, axis=1)\n",
    "    b = np.zeros((len(a), props.shape[1]))\n",
    "    b[np.arange(len(a)), a] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用sklearn\n",
    "predictions_last_epoch = model.predict(testX, batch_size = 16, verbose=1)\n",
    "predictions_last_epoch = props_to_onehot(predictions_last_epoch)\n",
    "target_names = ['CL', 'SW', 'CE', 'EM']\n",
    "print('\\n')\n",
    "print(classification_report(testY_binary, predictions_last_epoch, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((len(testY_binary)),len(predictions_last_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc = 'lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preData = [(np.argmax(one_hot)+1) for one_hot in predictions_last_epoch]\n",
    "trueData = [(np.argmax(one_hot)+1) for one_hot in testY_binary] \n",
    "time = np.arange(0,2395)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((len(preData)),len(trueData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计两个数字中，相同位置值不同的个数\n",
    "# 把预测错的值取出来\n",
    "n=0\n",
    "num = []\n",
    "preDataWrong = []\n",
    "trueDataTrue = []\n",
    "for i in range(0,len(preData)):\n",
    "    if preData[i] != trueData[i]:\n",
    "        num.append(i)\n",
    "        preDataWrong.append(preData[i])\n",
    "        trueDataTrue.append(trueData[i])\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n)\n",
    "print(num)\n",
    "print(preDataWrong)\n",
    "print(trueDataTrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time,preData,'r.',time,trueData,'b-')\n",
    "plt.draw()\n",
    "plt.savefig(\"predict\",dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplt = py.offline.plot\n",
    "predict = go.Scatter(\n",
    "    x = time, \n",
    "    y = preData,\n",
    "    name = 'predict'\n",
    ")\n",
    "true = go.Scatter(\n",
    "    x = time, \n",
    "    y = trueData,\n",
    "    mode = 'markers',\n",
    "    name = 'true'\n",
    ")\n",
    "predictWrong = go.Scatter(\n",
    "    x = num, \n",
    "    y = preDataWrong,\n",
    "    mode = 'markers',\n",
    "    name = 'predictWrong'\n",
    ")\n",
    "trueValue  = go.Scatter(\n",
    "    x = num, \n",
    "    y = trueDataTrue,\n",
    "    mode = 'markers',\n",
    "    name = 'trueValue'\n",
    ")\n",
    "\n",
    "data = [predict, true, predictWrong, trueValue]\n",
    "layout = go.Layout(\n",
    "    title = 'Y轴',\n",
    "    yaxis = dict(\n",
    "        title = 'predict'\n",
    "    ),\n",
    "    yaxis2 = dict(\n",
    "        title = 'true',\n",
    "        color = '#ffa631',\n",
    "        anchor = 'free',\n",
    "        overlaying = 'y',\n",
    "        side = 'left',\n",
    "        position = 0.04 \n",
    "    ),\n",
    "    yaxis3 = dict(\n",
    "        title = 'predictWrong',\n",
    "        color = '#75878a',\n",
    "        anchor = 'x',\n",
    "        overlaying = 'y',\n",
    "        side = 'right'\n",
    "    ),\n",
    "     yaxis4 = dict(\n",
    "        title = 'trueValue',\n",
    "        color = '#00e500',\n",
    "        anchor = 'free',\n",
    "        overlaying = 'y',\n",
    "        side = 'right',\n",
    "        position = 0.95\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data = data, layout=layout)\n",
    "plot_url = pyplt(fig, filename='ceshi.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
