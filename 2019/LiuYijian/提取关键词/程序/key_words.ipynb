{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主题1的关键词: ['文化遗产', '文化中心', '传统文化']\n",
      "主题2的关键词: ['知识产权', '科技创新', '科技创新中心']\n",
      "主题3的关键词: ['轨道交通', '基础设施', '美丽乡村']\n",
      "主题4的关键词: ['学前教育', '中小学生', '融合教育']\n",
      "主题5的关键词: ['共享单车', '老年代步车', '物业管理']\n",
      "主题6的关键词: ['垃圾分类', '资源回收', '建筑垃圾']\n",
      "主题7的关键词: ['分级诊疗', '医疗机构', '医疗服务']\n",
      "主题8的关键词: ['污泥利用', '污水处理', '污泥处理']\n"
     ]
    }
   ],
   "source": [
    "#将上述方法提取出来的关键词作为候选关键词，然后考虑每个候选关键词的前后词，根据词性确定是否可以组成候选关键词短语，统计每个簇中\n",
    "#候选关键词短语的次数，取出现次数最大的候选关键词短语作为关键词短语\n",
    "#!/usr/bin/python\n",
    "#-*- encoding:utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import jieba\n",
    "jieba.load_userdict('/Users/lyj/Desktop/提案程序/sogou.txt')\n",
    "jieba.load_userdict('/Users/lyj/Desktop/提案程序/标题补充词典.txt')\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "\n",
    "#读取stop停用词\n",
    "def readstopwords(stopwords_path):\n",
    "    stop_single_words=[]  \n",
    "    with open(stopwords_path,'r+',encoding='utf-8') as lines:\n",
    "        for line in lines:  \n",
    "            content=line.strip()  \n",
    "            stop_single_words.append(content) \n",
    "    return stop_single_words\n",
    "\n",
    "#分词\n",
    "def split_words(filePath,stop_single_words):\n",
    "    f = open(filePath,'r+',encoding='utf-8')\n",
    "    file_list = f.read()\n",
    "    f.close()\n",
    "\n",
    "    lis_before=[] #保存分词结果\n",
    "    seg_list = pseg.cut(file_list)\n",
    "    for seg,flag in seg_list: \n",
    "        seg = ''.join(seg.split())\n",
    "        lis_before.append((seg,flag)) \n",
    "    \n",
    "    file_list_after=re.sub('[A-Za-z0-9,\\d+(\\.\\d+)?\\%]','',file_list) #去除字母,数字,百分数\n",
    "    lis_after=[]\n",
    "    seg_list_after = pseg.cut(file_list_after)\n",
    "    for seg2,flag2 in seg_list_after: \n",
    "        seg2 = ''.join(seg2.split())\n",
    "        if seg2 not in stop_single_words and len(seg2)!=1:\n",
    "            lis_after.append((seg2,flag2)) \n",
    "    \n",
    "    return lis_before,lis_after\n",
    "\n",
    "#将聚类结果分词后，按字典保存\n",
    "def get_cluster_doc(savepath,stop_single_words):\n",
    "    cluster_words_dic={}\n",
    "    cluster_words_dic_after={}\n",
    "    for i in os.listdir(savepath):\n",
    "        if i!='.DS_Store':\n",
    "            words_list=[]\n",
    "            words_list_after=[]\n",
    "            path_file = os.path.join(savepath,i)  #取文件路径\n",
    "            for f in os.listdir(path_file): \n",
    "                if f!='.DS_Store':\n",
    "                    path_file2 =os.path.join(path_file,f)\n",
    "                    lis_before,lis_after=split_words(path_file2,stop_single_words)\n",
    "                    words_list.extend(lis_before)\n",
    "                    words_list_after.extend(lis_after)\n",
    "            cluster_words_dic[i]=words_list\n",
    "            cluster_words_dic_after[i]=words_list_after\n",
    "    return cluster_words_dic,cluster_words_dic_after\n",
    "\n",
    "#将候选关键词按字典保存\n",
    "def get_key_words(key_words_savepath):\n",
    "    key_words_dic={}\n",
    "    for i in os.listdir(key_words_savepath):\n",
    "        if i!='.DS_Store':\n",
    "            f = open(key_words_savepath+\"/\"+str(i),\"r+\",encoding=\"utf-8\")\n",
    "            key_words=f.read().strip().split()\n",
    "            f.close()\n",
    "            key_words_dic[i]=key_words\n",
    "    \n",
    "    return key_words_dic\n",
    "\n",
    "# def get_key_phrase(cluster_words_dic,key_words_dic):\n",
    "#     cluster_word_index_dic={}\n",
    "#     for key in key_words_dic.keys():\n",
    "#         cluster_list=[]\n",
    "#         for key_word in key_words_dic[key]:\n",
    "#             word_index=[]\n",
    "#             word_index_dic={}\n",
    "#             for item in enumerate(cluster_words_dic[key]):\n",
    "#                 if item[1][0]==key_word:\n",
    "#                     word_index.append(item[0])\n",
    "#             word_index_dic[key_word]=word_index\n",
    "#             cluster_list.append(word_index_dic)\n",
    "#         cluster_word_index_dic[key]=cluster_list\n",
    "#     return cluster_word_index_dic\n",
    "\n",
    "#根据候选关键词的前后词的词性确定是否可以组成关键词短语\n",
    "def get_key_phrase(cluster_words_dic_after,key_words_dic):\n",
    "    \n",
    "    part_speech=['n','nr','ns','nt','nz','vn','an','f']\n",
    "    key_phrase_dic_dic={}\n",
    "    key_phrase_list_dic={}\n",
    "    for key in key_words_dic.keys():\n",
    "        key_phrase_dic={}\n",
    "        key_phrase_list=[]\n",
    "        for key_word in key_words_dic[key]:\n",
    "            for item in enumerate(cluster_words_dic_after[key]): #enumerate用于查看指定值在列表中的所有位置\n",
    "                if item[1][0]==key_word:\n",
    "                    if len(item[1][0])>3:\n",
    "                        key_phrase_list.append(item[1][0])\n",
    "                        if item[1][0] not in key_phrase_dic.keys():\n",
    "                            key_phrase_dic[item[1][0]]=1\n",
    "                        else:\n",
    "                            key_phrase_dic[item[1][0]]+=1\n",
    "                    else:\n",
    "                        #列表中第一个词，没有前面的词\n",
    "                        if item[0]==0:\n",
    "                            if cluster_words_dic_after[key][item[0]+1][1] in part_speech: \n",
    "                                key_phrase=item[1][0]+cluster_words_dic_after[key][item[0]+1][0]\n",
    "                                key_phrase_list.append(key_phrase)\n",
    "                                if key_phrase not in key_phrase_dic.keys():\n",
    "                                    key_phrase_dic[key_phrase]=1\n",
    "                                else:\n",
    "                                    key_phrase_dic[key_phrase]+=1\n",
    "                            \n",
    "                        #列表中最后一个词，没有后面的词\n",
    "                        elif item[0]==len(cluster_words_dic_after[key])-1:\n",
    "                            if cluster_words_dic_after[key][item[0]-1][1] in part_speech:\n",
    "                                key_phrase=cluster_words_dic_after[key][item[0]-1][0]+item[1][0]\n",
    "                                key_phrase_list.append(key_phrase)\n",
    "                                if key_phrase not in key_phrase_dic.keys():\n",
    "                                    key_phrase_dic[key_phrase]=1\n",
    "                                else:\n",
    "                                    key_phrase_dic[key_phrase]+=1\n",
    "                            \n",
    "                        #列表中中间位置的词\n",
    "                        else:\n",
    "                            if cluster_words_dic_after[key][item[0]-1][1] in part_speech and cluster_words_dic_after[key][item[0]+1][1] not in part_speech:\n",
    "                                key_phrase=cluster_words_dic_after[key][item[0]-1][0]+item[1][0]\n",
    "                                key_phrase_list.append(key_phrase)\n",
    "                                if key_phrase not in key_phrase_dic.keys():\n",
    "                                    key_phrase_dic[key_phrase]=1\n",
    "                                else:\n",
    "                                    key_phrase_dic[key_phrase]+=1\n",
    "                            if cluster_words_dic_after[key][item[0]+1][1] in part_speech and cluster_words_dic_after[key][item[0]-1][1] not in part_speech:\n",
    "                                key_phrase=item[1][0]+cluster_words_dic_after[key][item[0]+1][0]\n",
    "                                key_phrase_list.append(key_phrase)\n",
    "                                if key_phrase not in key_phrase_dic.keys():\n",
    "                                    key_phrase_dic[key_phrase]=1\n",
    "                                else:\n",
    "                                    key_phrase_dic[key_phrase]+=1\n",
    "                            if cluster_words_dic_after[key][item[0]+1][1] in part_speech and cluster_words_dic_after[key][item[0]-1][1] in part_speech:\n",
    "                                key_phrase=cluster_words_dic_after[key][item[0]-1][0]+item[1][0]+cluster_words_dic_after[key][item[0]+1][0]\n",
    "                                key_phrase_list.append(key_phrase)\n",
    "                                if key_phrase not in key_phrase_dic.keys():\n",
    "                                    key_phrase_dic[key_phrase]=1\n",
    "                                else:\n",
    "                                    key_phrase_dic[key_phrase]+=1\n",
    "                            \n",
    "        key_phrase_dic_dic[key]=key_phrase_dic\n",
    "        key_phrase_list_dic[key]=key_phrase_list\n",
    "    return key_phrase_dic_dic,key_phrase_list_dic\n",
    "\n",
    "def compare(key_phrase_dic_before,key_phrase_list_before,key_phrase_dic_after,key_phrase_list_after):\n",
    "    dic={}\n",
    "    for key in key_phrase_list_before.keys():\n",
    "        Intersection=list(set(key_phrase_list_before[key]).intersection(set(key_phrase_list_after[key])))\n",
    "        for word in key_phrase_dic_after[key].keys():\n",
    "            if word not in Intersection:\n",
    "                key_phrase_dic_after[key][word]=-1\n",
    "        if key=='1.txt':\n",
    "            dic[1]=sorted(key_phrase_dic_after[key].items(),key = lambda x:x[1],reverse = True)[:3]\n",
    "        if key=='2.txt':\n",
    "            dic[2]=sorted(key_phrase_dic_after[key].items(),key = lambda x:x[1],reverse = True)[:3]\n",
    "        if key=='3.txt':\n",
    "            dic[3]=sorted(key_phrase_dic_after[key].items(),key = lambda x:x[1],reverse = True)[:3]\n",
    "        if key=='4.txt':\n",
    "            dic[4]=sorted(key_phrase_dic_after[key].items(),key = lambda x:x[1],reverse = True)[:3]\n",
    "        if key=='5.txt':\n",
    "            dic[5]=sorted(key_phrase_dic_after[key].items(),key = lambda x:x[1],reverse = True)[:3]\n",
    "        if key=='6.txt':\n",
    "            dic[6]=sorted(key_phrase_dic_after[key].items(),key = lambda x:x[1],reverse = True)[:3]\n",
    "        if key=='7.txt':\n",
    "            dic[7]=sorted(key_phrase_dic_after[key].items(),key = lambda x:x[1],reverse = True)[:3]\n",
    "        if key=='8.txt':\n",
    "            dic[8]=sorted(key_phrase_dic_after[key].items(),key = lambda x:x[1],reverse = True)[:3]\n",
    "    return dic\n",
    "\n",
    "stopwords_path=\"/Users/lyj/Desktop/提案程序/百度停用词列表（去除英文）+tycb_symbol1.txt\"\n",
    "savepath=\"/Users/lyj/Desktop/提案程序/word2veccluster\" #保存聚类结果\n",
    "key_words_savepath=\"/Users/lyj/Desktop/提案程序/候选关键词\"\n",
    "\n",
    "stop_single_words=readstopwords(stopwords_path)\n",
    "cluster_words_dic,cluster_words_dic_after=get_cluster_doc(savepath,stop_single_words) #将聚类后的文档根据是否去除停用词分别按字典保存\n",
    "key_words_dic=get_key_words(key_words_savepath) #将候选关键词按字典保存\n",
    "key_phrase_dic_before,key_phrase_list_before=get_key_phrase(cluster_words_dic,key_words_dic) #得到未去除停用词的候选关键词短语\n",
    "key_phrase_dic_after,key_phrase_list_after=get_key_phrase(cluster_words_dic_after,key_words_dic) #得到去除停用词的候选关键词短语\n",
    "dic=compare(key_phrase_dic_before,key_phrase_list_before,key_phrase_dic_after,key_phrase_list_after) #两者比较得到最终的关键词短语\n",
    "for i in sorted(dic.items(),key = lambda x:x[0]):\n",
    "    word=[]\n",
    "    for j in i[1]:\n",
    "        word.append(j[0])\n",
    "    print(\"主题\"+str(i[0])+\"的关键词:\",word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
